{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Project 2: The Perceptron</h2>\n",
    "\n",
    "\n",
    "<!--announcements-->\n",
    "<blockquote>\n",
    "    <center>\n",
    "    <img src=\"perceptron.png\" width=\"200px\" />\n",
    "    </center>\n",
    "      <p><cite><center>\"What, we asked, wasn't the Perceptron capable of?\"<br>\n",
    "      Rival, The New Yorker, December 6, 1958 P. 44</center>\n",
    "      </cite></p>\n",
    "</blockquote>\n",
    "\n",
    "<h3>Introduction</h3>\n",
    "<!--AÃ°albrandr-->\n",
    "\n",
    "<p>In this project, you will implement a simple Perceptron classifier to classify digits (or anything else).</p>\n",
    "\n",
    "<strong>How to submit:</strong> You can submit your code using the red <strong>Submit</strong> button above. This button will send any code below surrounded by <strong>#&lt;GRADED&gt;</strong><strong>#&lt;/GRADED&gt;</strong> tags below to the autograder, which will then run several tests over your code. By clicking on the <strong>Details</strong> dropdown next to the Submit button, you will be able to view your submission report once the autograder has completed running. This submission report contains a summary of the tests you have failed or passed, as well as a log of any errors generated by your code when we ran it.\n",
    "\n",
    "Note that this may take a while depending on how long your code takes to run! Once your code is submitted you may navigate away from the page as you desire -- the most recent submission report will always be available from the Details menu.\n",
    "\n",
    "<p><strong>Evaluation:</strong> Your code will be autograded for technical\n",
    "correctness. Please <em>do not</em> change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation -- not the autograder's output -- will be the final judge of your score.  If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.\n",
    "\n",
    "<p><strong>Academic Dishonesty:</strong> We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else's code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don't try. We trust you all to submit your own work only; <em>please</em> don't let us down. If you do, we will pursue the strongest consequences available to us.\n",
    "\n",
    "<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course staff for help.  Office hours, section, and the <a href=\"https://piazza.com/class/icxgflcnpra3ko\">Piazza</a> are there for your support; please use them.  If you can't make our office hours, let us know and we will schedule more.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.  \n",
    "\n",
    "<h3> The Perceptron </h3>\n",
    "\n",
    "<p>The perceptron is a basic linear classifier. The following questions will ask you to finish these functions in a pre-defined order. Unless specified otherwise, do not use loops.<br></p>\n",
    "\n",
    "<p>(a) Implement the process of updating the weight vector in the following function. (Hint: In Julia, if you compute <code>p=v*w'</code> for row vectors <code>v,w</code>, the output <code>p</code> will be an array. You can call <code>p=p[1]</code> to cast it as a scalar.)  \n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "import numpy as np\n",
    "from numpy.matlib import repmat\n",
    "#</GRADED>\n",
    "import sys\n",
    "import matplotlib \n",
    "matplotlib.use('PDF')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "# add p02 folder\n",
    "sys.path.insert(0, './p02/')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.5.2\n"
     ]
    }
   ],
   "source": [
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loaddata(filename):\n",
    "    \"\"\"\n",
    "    Returns xTr,yTr,xTe,yTe\n",
    "    xTr, xTe are in the form nxd\n",
    "    yTr, yTe are in the form nx1\n",
    "    \"\"\"\n",
    "    data = loadmat(filename)\n",
    "    xTr = data[\"xTr\"]; # load in Training data\n",
    "    yTr = np.round(data[\"yTr\"]); # load in Training labels\n",
    "    xTe = data[\"xTe\"]; # load in Testing data\n",
    "    yTe = np.round(data[\"yTe\"]); # load in Testing labels\n",
    "    return xTr.T,yTr.T,xTe.T,yTe.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def row_vectorize(x):\n",
    "    return x.reshape(1,-1)\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def perceptronUpdate(x,y,w):\n",
    "    \"\"\"\n",
    "    function w=perceptronUpdate(x,y,w);\n",
    "    \n",
    "    Implementation of Perceptron weights updating\n",
    "    Input:\n",
    "    x : input vector of d dimensions (1xd)\n",
    "    y : corresponding label (-1 or +1)\n",
    "    w : weight vector before updating\n",
    "    \n",
    "    Output:\n",
    "    w : weight vector after updating\n",
    "    \"\"\"\n",
    "    # just in case x, w are accidentally transposed (prevents future bugs)\n",
    "    #x,w = map(row_vectorize, [x,w])\n",
    "    \n",
    "    assert(y in [1,-1])\n",
    "    ## fill in code here\n",
    "    w = w + y*x\n",
    "    return w\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[2 3 4]\n",
      " [5 6 7]]\n",
      "[[ 1  1  1]\n",
      " [-1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = np.array([[2,3,4],[5,6,7]])\n",
    "c = np.array([[1,1,1],[-1,-1,-1]])\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a=a.reshape(1,-1)\n",
    "b=b.reshape(1,-1)\n",
    "c=c.reshape(1,-1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7, 13, 19, 29, 41]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b+c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(b) Implement function <b><code>perceptron</code></b>. This should contain a loop that calls \n",
    "<b><code>perceptronUpdate</code></b>\n",
    " until it converges or the maximum iteration count, 100, has been reached.\n",
    " Make sure you randomize the order of the training data on each iteration. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def perceptron(x,y):\n",
    "    \"\"\"\n",
    "    function w=perceptron(x,y);\n",
    "    \n",
    "    Implementation of a Perceptron classifier\n",
    "    Input:\n",
    "    x : n input vectors of d dimensions (nxd)\n",
    "    y : n labels (-1 or +1)\n",
    "    \n",
    "    Output:\n",
    "    w : weight vector (1xd)\n",
    "    \"\"\"\n",
    "    \n",
    "    n, d = x.shape\n",
    "    w = np.zeros((1,d))\n",
    "    \n",
    "    ## fill in code here\n",
    "    niter = 0\n",
    "    while True:\n",
    "        m = 0\n",
    "        niter = niter + 1\n",
    "        index = np.random.permutation(range(n)) # randomness affects the order of w getting updated.\n",
    "        for i in index:\n",
    "            if (y[i] * np.matmul(x, w.T)[i]) <= 0:\n",
    "                w = perceptronUpdate(x[i],y[i],w)\n",
    "                m = m + 1\n",
    "        if m == 0 or niter == 100:\n",
    "            break\n",
    "    return w\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "[[  5 100]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[205],\n",
       "       [415],\n",
       "       [625],\n",
       "       [835]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "# n, d = x.shape\n",
    "# w = np.zeros((1,d))\n",
    "w = np.array([[5,100]])\n",
    "print(x)\n",
    "print(w)\n",
    "np.matmul(x,w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(c) \n",
    "\tImplement \n",
    "<b><code>classifyLinear</code></b>\n",
    " that applies the weight vector and bias to the input vector. (The bias is an optional parameter. If it is not passed in, assume it is zero.) Make sure that the predictions returned are either 1 or -1.</p> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "\n",
    "def classifyLinear(x,w,b=0):\n",
    "    \"\"\"\n",
    "    function preds=classifyLinear(x,w,b)\n",
    "    \n",
    "    Make predictions with a linear classifier\n",
    "    Input:\n",
    "    x : n input vectors of d dimensions (nxd)\n",
    "    w : weight vector (1xd)\n",
    "    b : bias (scalar)\n",
    "    \n",
    "    Output:\n",
    "    preds: predictions (nx1) \n",
    "    \"\"\"\n",
    "    # w = w.reshape(-1)\n",
    "    ## fill in code here\n",
    "#    x = x.reshape(1,256)\n",
    "    print(\"input x dim:\", x.shape)\n",
    "    preds = np.zeros((x.shape[0], 1))  ## dimension should be nx1 instead of 1xn\n",
    "    for j in range(x.shape[0]):\n",
    "        if np.matmul(x[j], w.T) + b > 0:\n",
    "            preds[j] = 1\n",
    "        else:\n",
    "            preds[j] = -1\n",
    "    return preds.reshape(1, x.shape[0])\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((10,1))\n",
    "z.shape\n",
    "print(z[0])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p> You can use the following script to visualize your perceptron on linearly separable data in 2 dimensions. Your classifier should find a separating hyperplane on such data.   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYWAnIkqY/wdWwsP3a88ZXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe60c9c47f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of input vectors\n",
    "N = 100\n",
    "# Define the symbols and colors we'll use in the plots later\n",
    "symbols = ['ko', 'kx']\n",
    "mycolors = [[0.5, 0.5, 1], [1, 0.5, 0.5]]\n",
    "classvals = [-1, 1]\n",
    "\n",
    "# generate random (linarly separable) data\n",
    "trainPoints = np.random.randn(N, 2) * 1.5\n",
    "\n",
    "# defining random hyperplane\n",
    "w = np.random.rand(2)\n",
    "\n",
    "# assigning labels +1, -1 labels depending on what side of the plane they lie on\n",
    "trainLabels = np.sign(np.dot(trainPoints, w))\n",
    "i = np.random.permutation([i for i in range(N)])\n",
    "\n",
    "# shuffling training points in random order\n",
    "trainPoints = trainPoints[i, :]\n",
    "trainLabels = trainLabels[i]\n",
    "\n",
    "# call perceptron to find w from data\n",
    "w = perceptron(trainPoints.copy(),trainLabels.copy())\n",
    "b = 0\n",
    "\n",
    "res=300\n",
    "xrange = np.linspace(-5, 5,res)\n",
    "yrange = np.linspace(-5, 5,res)\n",
    "pixelX = repmat(xrange, res, 1)\n",
    "pixelY = repmat(yrange, res, 1).T\n",
    "\n",
    "testPoints = np.array([pixelX.flatten(), pixelY.flatten(), np.ones(pixelX.flatten().shape)]).T\n",
    "testLabels = np.dot(testPoints, np.concatenate([w.flatten(), [b]]))\n",
    "\n",
    "Z = testLabels.reshape(res,res)\n",
    "plt.contourf(pixelX, pixelY, np.sign(Z), colors=mycolors)\n",
    "plt.scatter(trainPoints[trainLabels == classvals[0],0],\n",
    "            trainPoints[trainLabels == classvals[0],1],\n",
    "            marker='o',\n",
    "            color='k'\n",
    "           )\n",
    "plt.scatter(trainPoints[trainLabels == classvals[1],0],\n",
    "            trainPoints[trainLabels == classvals[1],1],\n",
    "            marker='x',\n",
    "            color='k'\n",
    "           )\n",
    "plt.quiver(0,0,w[0,0],w[0,1],linewidth=0.5, color=[0,1,0])\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hints</h3>\n",
    "<tr><td><code>randperm </code></td><td>Returns a vector with the numbers [1,n] in a random permutation.</td></tr>\n",
    "\n",
    "<h4>Credits</h4>\n",
    "  Parts of this webpage were copied from or heavily inspired by John DeNero's and Dan Klein's (awesome) <a href=\"http://ai.berkeley.edu/project_overview.html\">Pacman class</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(x, val):\n",
    "    z = np.zeros(x.shape)\n",
    "    z[x != val] = 0\n",
    "    z[x == val] = 1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p> You can use the following script to visualize the weight vector and classification error on the digits data set. Your perceptron should be able to find a separating hyperplane for this data. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x dim: (100, 256)\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "input x dim: (100, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-11069eb0f2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#        if classifyLinear(xTr[i,:], w) != yTr[i]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifyLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclassifyLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0myTr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m# do update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptronUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAACcCAYAAAC3D/QCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVswJxMyKOYGYWTEnEDMr5gRiZsX+H201J+BuPqEkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe60c8935f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "xTr,yTr,xTe,yTe=loaddata(\"digits.mat\")\n",
    "MAXITER = 10\n",
    "N = 100\n",
    "c = [0, 7]\n",
    "\n",
    "ii = np.where(np.logical_or(yTr == c[0], yTr == c[1]).flatten())[0]\n",
    "ii = ii[np.random.permutation([i for i in range(len(ii))])]\n",
    "ii = ii[:N]\n",
    "\n",
    "xTr = xTr[ii,:]\n",
    "yTr = yTr[ii].flatten()\n",
    "yTr = binarize(yTr, c[0]) * 2 - 1\n",
    "\n",
    "n = 2    \n",
    "size = 2\n",
    "f, axarr = plt.subplots(1, n, sharey=True)\n",
    "f.set_figwidth(size * n)\n",
    "f.set_figheight(size /2 *n)\n",
    "\n",
    "w = np.zeros(xTr[0,:].shape)\n",
    "err = 1.0\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# run at most MAXITER iterations\n",
    "for itr in range(MAXITER):\n",
    "    for i in range(N):\n",
    "        # draw offender\n",
    "        axarr[1].imshow(xTr[i,:].reshape(16,16).T, cmap=plt.cm.binary_r)\n",
    "        axarr[1].tick_params(axis='both', which='both', bottom='off', top='off',\n",
    "                             labelbottom='off', right='off', left='off', labelleft='off')\n",
    "        axarr[1].set_title('Last Incorrect Sample')\n",
    "        \n",
    "#        print(classifyLinear(xTr[i,:], w))\n",
    "#        print(yTr[i])\n",
    "#        print(xTr.shape)\n",
    "#        if classifyLinear(xTr[i,:], w) != yTr[i]:\n",
    "        print(classifyLinear(xTr, w)[i])\n",
    "        if classifyLinear(xTr, w)[i] != yTr[i]:\n",
    "            # do update\n",
    "            w = perceptronUpdate(xTr[i,:], yTr[i], w)\n",
    "            # compute new training error\n",
    "            preds = classifyLinear(xTr, w)\n",
    "            err = np.sum(yTr == preds) / float(len(yTr))\n",
    "\n",
    "            # plot new vector\n",
    "            axarr[0].imshow(w.reshape(16,16).T, cmap=plt.cm.binary_r)\n",
    "            axarr[0].tick_params(axis='both', which='both', bottom='off', top='off',\n",
    "                                 labelbottom='off', right='off', left='off', labelleft='off')\n",
    "            axarr[0].set_title('Weight Vector')\n",
    "            axarr[0].set_xlabel('Acurracy: %.2f' % err)\n",
    "            \n",
    "            display.display(pl.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        if err == 0.:\n",
    "            break\n",
    "    time.sleep(0.01)\n",
    "    \n",
    "    if err == 0.:\n",
    "        break\n",
    "\n",
    "axarr[1].set_xlabel('Done!')\n",
    "display.display(pl.gcf())\n",
    "display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
